# -*- coding: utf-8 -*-
#"""Jorge Riquelme  UDD_Proyecto M7 play store

#Automatically generated by Colaboratory.

#Original file is located at
#    https://colab.research.google.com/drive/1jHrXH_QGmim3YYJ-813fDgLz3Yxru2a8

## **Bootcamp: Ciencia de Datos e Inteligencia Artificial**
## **Proyecto del Módulo 7: Técnicas avanzadas para ciencia de datos y empleabilidad**

#Hola, ya es el último proyecto, has avanzado y aprendido mucho hasta acá. ¡Muchas felicidades!

#Es hora de poner en práctica todo lo que hemos aprendido a lo largo de nuestra travesía.

#Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que lo concluyas de manera sobresaliente.

#¡Éxito!

# Objetivos
#- Aplicar con éxito todos los conocimientos que has adquirido a lo largo del Bootcamp.
#- Consolidar las técnicas de limpieza, entrenamiento, graficación y ajuste a modelos de *Machine Learning*.
#- Generar una API que brinde predicciones como resultado a partir de datos enviados.

# Proyecto

#1. Selecciona uno de los siguientes *datasets*:
#  - Imágenes de rayos X de pecho para detectar neumonía: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
#  - *Reviews* de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps
#  - Estadísticas demográficas de los ganadores del premio Oscar de la Academia: https://www.kaggle.com/datasets/fmejia21/demographics-of-academy-awards-oscars-winners
#  - Aspiraciones profesionales de la generación Z: https://www.kaggle.com/datasets/kulturehire/understanding-career-aspirations-of-genz

#Cada uno representa un *dataset*, un problema y una forma diferente de abordarlo. Tu tarea es identificar las técnicas y modelos que podrías usar para tu proyecto.

#2. Debes hacer un análisis exploratorio y limpieza de los datos. Usa las ténicas que creas convenientes.

#3. Entrena el modelo de *Machine Learning*, procesamiento de lenguaje natural o red neuronal que creas adecuado.

#4. Genera por lo menos dos gráficas y dos métricas de rendimiento; explica las puntuaciones de rendimiento que amerite tu problema. Todas las gráficas de rendimiento que realices deben tener leyendas, colores y títulos personalizados por ti.

#  - Además, antes de subir el modelo a "producción", deberás realizar un proceso de ensambles (*ensemblings*) y de ajuste de hiperparámetros o *tuning* para intentar mejorar la precisión y disminuir la varianza de tu modelo.

#5. Construye una API REST en la que cualquier usuario pueda mandar datos y que esta misma devuelva la predicción del modelo que has hecho. La API debe estar en la nube, ya sea en un servicio como Netlify o Ngrok, para que pueda ser consultada desde internet.

#6. Genera una presentación del problema y del modelo de solución que planteas. Muestra gráficas, datos de rendimiento y explicaciones. Esta presentación debe estar enfocada a personas que no sepan mucho de ciencia de datos e inteligencia artificial.

#7. **Solamente se recibirán trabajos subidos a tu cuenta de GitHub con un README.md apropiado que explique tu proyecto**.

## Criterios de evaluación

#| Actividad | Porcentaje | Observaciones | Punto parcial
#| -- | -- | -- | -- |
#| Actividad 1. Limpieza y EDA | 20 | Realiza todas las tareas necesarias para hacer el EDA y la limpieza correcta, dependiendo de la problemática. Debes hacer como mínimo el análisis de completitud, escalamiento (si aplica) y tokenización (si aplica). | Realizaste solo algunas tareas de exploración y limpieza y el modelo se muestra aún con oportunidad de completitud, escalamiento y/o mejora. |
#| Actividad 2. Entrenamiento del modelo | 20 | Elige el modelo y algoritmo adecuados para tu problema, entrénalo con los datos ya limpios y genera algunas predicciones de prueba. | No has realizado predicciones de prueba para tu modelo de ML y/o tu modelo muestra una precisión menor al 60 %. |
#| Actividad 3. Graficación y métricas | 20 | Genera por lo menos dos gráficas y dos muestras de métricas que permitan visualizar el rendimiento y precisión del modelo que construiste. Además, realizaste los procesos de *tuning* y ensambles adecuados para tu problema. | Las gráficas no tienen leyendas y colores customizados, solo muestras una gráfica o no realizaste el *tuning* de hiperparámetros.
#| Actividad 4. API REST | 20 | Generaste con éxito un *link* público en el que, por método POST, se puede mandar información y la API REST devuelve una predicción junto con el porcentaje de confianza de esta misma. | N/A
#| Actividad 5. Presentación | 20 | Genera una presentación en la que establezcas como mínimo: el problema, proceso de solución, metodologías usadas, gráficas de rendimiento, demostración del modelo y aprendizajes obtenidos. Debes redactarla con términos que pueda entender cualquier persona, no solo científicos de datos. | La presentación no expone con claridad o en términos coloquiales el proceso de creación del modelo, sus ventajas y muestras de rendimiento.

#**Mucho éxito en tu camino como Data Scientist.**

#Se elige para el desarrollo de la tarea Reviews de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps
#"""

#from google.colab import drive
#drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el DataFrame
df = pd.read_csv('C:\Users\cathe\Downloads\Python\googleplaystore.csv')

# Mostrar información general del DataFrame
print(df.info())

#visualizamos la tabla
df.head()

# Análisis Exploratorio de Datos (EDA)
# Histograma de Ratings
plt.figure(figsize=(8, 6))
sns.histplot(df['Rating'], bins=30, kde=True, color='blue')
plt.title('Distribución de Ratings')
plt.xlabel('Rating')
plt.ylabel('Frecuencia')
plt.show()

# Boxplot para identificar outliers
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['Rating'], color='green')
plt.title('Boxplot de Ratings')
plt.xlabel('Rating')
plt.show()

# Matriz de correlación
correlation_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matriz de Correlación')
plt.show()

# Limpieza de Datos y eliminacion de valores nulos
df.dropna(inplace=True)

# Eliminar duplicados
df.drop_duplicates(inplace=True)

# Convertir 'Reviews' a numérico
df['Reviews'] = pd.to_numeric(df['Reviews'], errors='coerce')

# Eliminar filas con valores nulos en 'Reviews'
df = df.dropna(subset=['Reviews'])

# Convertir 'Size' a numérico
df['Size'] = df['Size'].apply(lambda x: str(x).replace('M', '') if 'M' in str(x) else str(x))
df['Size'] = df['Size'].apply(lambda x: str(x).replace('k', '') if 'k' in str(x) else str(x))
df['Size'] = pd.to_numeric(df['Size'], errors='coerce')

# Eliminar filas con valores nulos en 'Size'
df = df.dropna(subset=['Size'])

# Mostrar información actualizada del DataFrame
print(df.info())

df.head()

# Eliminar el signo '+' de la columna 'Installs'
df['Installs'] = df['Installs'].str.replace('+', '', regex=False)

# Convertir la columna 'Installs' a numérica
df['Installs'] = pd.to_numeric(df['Installs'].str.replace(',', ''), errors='coerce')

# Verificar los cambios
print(df['Installs'].head())

#volvemos a verificar como va el DF
df.head()

print(df.info())

# Remuevo el signo '$'
df['Price'] = df['Price'].apply(lambda x: x.replace('$', "") if '$' in str(x) else x)
df['Price'] = df['Price'].apply(lambda x: x.replace('Everyone', "") if 'Everyone' in str(x) else x)
df['Price'] = pd.to_numeric(df['Price'], errors='coerce')

print(df.info())

#Regresión para predecir la calificación (Rating) de una aplicación en función de otras características.

# Selección de características y variable objetivo
X_reg = df[['Reviews', 'Size', 'Installs','Price']]
y_reg = df['Rating']

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# División de datos
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# Modelo de Regresión Lineal
model_reg = LinearRegression()
model_reg.fit(X_train_reg, y_train_reg)

# Predicciones
y_pred_reg = model_reg.predict(X_test_reg)

# Métricas de Rendimiento para Regresión
mse_reg = mean_squared_error(y_test_reg, y_pred_reg)
r2_reg = r2_score(y_test_reg, y_pred_reg)

print(f'Mean Squared Error (Regresión): {mse_reg}')
print(f'R² Score (Regresión): {r2_reg}')

#Clasificación para predecir la categoría de una aplicación

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# Categorización de la variable objetivo
le = LabelEncoder()
df['CategoryEncoded'] = le.fit_transform(df['Category'])

# Selección de características y variable objetivo
X_cls = df[['Reviews', 'Size', 'Installs','Price']]
y_cls = df['CategoryEncoded']

# División de datos
X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)

# Modelo de Clasificación (Random Forest)
model_cls = RandomForestClassifier()
model_cls.fit(X_train_cls, y_train_cls)

# Predicciones
y_pred_cls = model_cls.predict(X_test_cls)

# Métricas de Rendimiento para Clasificación
accuracy_cls = accuracy_score(y_test_cls, y_pred_cls)
conf_matrix_cls = confusion_matrix(y_test_cls, y_pred_cls)
cls_report_cls = classification_report(y_test_cls, y_pred_cls)

print(f'Accuracy (Clasificación): {accuracy_cls}')
print('Confusion Matrix (Clasificación):\n', conf_matrix_cls)
print('Classification Report (Clasificación):\n', cls_report_cls)

#Gráficas y Métricas para la Regresión (Predicción de Rating)

import matplotlib.pyplot as plt
import seaborn as sns

# Gráfica 1: Predicciones vs. Valores reales para Regresión
plt.figure(figsize=(10, 6))
plt.scatter(y_test_reg, y_pred_reg, color='blue', alpha=0.5)
plt.title('Predicciones vs. Valores reales para Regresión')
plt.xlabel('Valores reales')
plt.ylabel('Predicciones')
plt.show()

# Gráfica 2: Distribución de Residuos para Regresión
residuos = y_test_reg - y_pred_reg
plt.figure(figsize=(10, 6))
sns.histplot(residuos, kde=True, color='green')
plt.title('Distribución de Residuos para Regresión')
plt.xlabel('Residuos')
plt.ylabel('Frecuencia')
plt.show()

# Métricas de Rendimiento para Regresión
# (ya calculadas en el código anterior)
print(f'Mean Squared Error (Regresión): {mse_reg}')
print(f'R² Score (Regresión): {r2_reg}')

#Gráficas y Métricas para la Clasificación (Predicción de Categoría)

import numpy as np

# Gráfica 3: Matriz de Confusión para Clasificación
plt.figure(figsize=(10, 6))
sns.heatmap(conf_matrix_cls, annot=True, cmap='YlGnBu', fmt='g')
plt.title('Matriz de Confusión para Clasificación')
plt.xlabel('Predicciones')
plt.ylabel('Valores reales')
plt.show()

#Se utilizaran tecnicas de ensamblado y y ajuste de hiperparametros para mejorar la precisión y disminuir la varianza de los modelos

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# Modelo de Bosque Aleatorio para Regresión
model_reg_ensamble = RandomForestRegressor()

# Parámetros para ajuste
param_grid_reg = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Búsqueda grid para ajuste de hiperparámetros
grid_search_reg = GridSearchCV(estimator=model_reg_ensamble, param_grid=param_grid_reg, scoring='neg_mean_squared_error', cv=3)
grid_search_reg.fit(X_reg, y_reg)

# Mejores hiperparámetros encontrados
best_params_reg = grid_search_reg.best_params_

# Modelo final con mejores hiperparámetros
model_reg_final = grid_search_reg.best_estimator_

# Métricas de rendimiento para el modelo final
y_pred_reg_final = model_reg_final.predict(X_test_reg)
mse_reg_final = mean_squared_error(y_test_reg, y_pred_reg_final)
r2_reg_final = r2_score(y_test_reg, y_pred_reg_final)

print(f'Mejores hiperparámetros para Regresión: {best_params_reg}')
print(f'Mean Squared Error (Regresión - Después del ajuste): {mse_reg_final}')
print(f'R² Score (Regresión - Después del ajuste): {r2_reg_final}')

# Modelo de Bosque Aleatorio para Clasificación
model_cls_ensamble = RandomForestClassifier()

# Parámetros para ajuste
param_grid_cls = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Búsqueda grid para ajuste de hiperparámetros
grid_search_cls = GridSearchCV(estimator=model_cls_ensamble, param_grid=param_grid_cls, scoring='accuracy', cv=3)
grid_search_cls.fit(X_cls, y_cls)

# Mejores hiperparámetros encontrados
best_params_cls = grid_search_cls.best_params_

# Modelo final con mejores hiperparámetros
model_cls_final = grid_search_cls.best_estimator_

# Métricas de rendimiento para el modelo final
y_pred_cls_final = model_cls_final.predict(X_test_cls)
accuracy_cls_final = accuracy_score(y_test_cls, y_pred_cls_final)

print(f'Mejores hiperparámetros para Clasificación: {best_params_cls}')
print(f'Accuracy (Clasificación - Después del ajuste): {accuracy_cls_final}')